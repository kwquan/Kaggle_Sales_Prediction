{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "main = pd.read_csv(\"sales_train\")\n",
    "test = pd.read_csv(\"sales_test\")\n",
    "shops = pd.read_csv('shops')\n",
    "items = pd.read_csv('items')\n",
    "cats = pd.read_csv('item_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
       "0  02.01.2013               0       59    22154      999.00           1.0\n",
       "1  03.01.2013               0       25     2552      899.00           1.0\n",
       "2  05.01.2013               0       25     2552      899.00          -1.0\n",
       "3  06.01.2013               0       25     2554     1709.05           1.0\n",
       "4  15.01.2013               0       25     2555     1099.00           1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  shop_id  item_id\n",
       "0   0        5     5037\n",
       "1   1        5     5320\n",
       "2   2        5     5233\n",
       "3   3        5     5232\n",
       "4   4        5     5268"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              0\n",
       "date_block_num    0\n",
       "shop_id           0\n",
       "item_id           0\n",
       "item_price        0\n",
       "item_cnt_day      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NULL DATA CHECK\n",
    "#Check for missing values\n",
    "main.isnull().sum()\n",
    "#No columns contain null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA LEAK\n",
    "#We check if all shop_id in test is found in train\n",
    "test['shop_id'].unique().any() not in main['shop_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA LEAK\n",
    "#We check if all item_id in test is found in train\n",
    "test['item_id'].unique().any() not in main['item_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS WHERE WE REMOVE OUTLIERS\n",
    "#REFER TO EDA SECTION FOR CHOICE OF THRESHOLDS\n",
    "leak_train = main\n",
    "leak_train = leak_train[leak_train['item_price']<100000]\n",
    "leak_train = leak_train[leak_train['item_cnt_day']<1001]\n",
    "#There exist one negative price. Replace it with median\n",
    "median = leak_train[(leak_train.shop_id==32)&(leak_train.item_id==2973)&(leak_train.date_block_num==4)&(leak_train.item_price>0)].item_price.median()\n",
    "leak_train.loc[leak_train.item_price<0, 'item_price'] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, date_block_num, shop_id, item_id, item_price, item_cnt_day]\n",
       "Index: []"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Info for transaction with negative price\n",
    "leak_train[leak_train['item_price'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date_block_num</th>\n",
       "      <td>2935847.0</td>\n",
       "      <td>14.569906</td>\n",
       "      <td>9.422985</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id</th>\n",
       "      <td>2935847.0</td>\n",
       "      <td>33.001743</td>\n",
       "      <td>16.226969</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <td>2935847.0</td>\n",
       "      <td>10197.228064</td>\n",
       "      <td>6324.299011</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4476.0</td>\n",
       "      <td>9343.0</td>\n",
       "      <td>15684.0</td>\n",
       "      <td>22169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_price</th>\n",
       "      <td>2935847.0</td>\n",
       "      <td>890.749575</td>\n",
       "      <td>1720.490363</td>\n",
       "      <td>0.07</td>\n",
       "      <td>249.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>59200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_cnt_day</th>\n",
       "      <td>2935847.0</td>\n",
       "      <td>1.241903</td>\n",
       "      <td>2.292963</td>\n",
       "      <td>-22.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count          mean          std    min     25%     50%  \\\n",
       "date_block_num  2935847.0     14.569906     9.422985   0.00     7.0    14.0   \n",
       "shop_id         2935847.0     33.001743    16.226969   0.00    22.0    31.0   \n",
       "item_id         2935847.0  10197.228064  6324.299011   0.00  4476.0  9343.0   \n",
       "item_price      2935847.0    890.749575  1720.490363   0.07   249.0   399.0   \n",
       "item_cnt_day    2935847.0      1.241903     2.292963 -22.00     1.0     1.0   \n",
       "\n",
       "                    75%      max  \n",
       "date_block_num     23.0     33.0  \n",
       "shop_id            47.0     59.0  \n",
       "item_id         15684.0  22169.0  \n",
       "item_price        999.0  59200.0  \n",
       "item_cnt_day        1.0   1000.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leak_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#REFER TO EDA SECTION FOR DUPLICATES CHECK\n",
    "#Some shops are duplicates. We fix them with the same shop_id\n",
    "leak_train.loc[leak_train['shop_id'] == 0,'shop_id'] = 57\n",
    "test.loc[test['shop_id'] == 0,'shop_id'] = 57\n",
    "leak_train.loc[leak_train['shop_id'] == 1,'shop_id'] = 58\n",
    "test.loc[test['shop_id'] == 1,'shop_id'] = 58\n",
    "leak_train.loc[leak_train['shop_id'] == 10,'shop_id'] = 11\n",
    "test.loc[test['shop_id'] == 10,'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN EDA SECTION FIRST BEFORE MOVING ON TO THE NEXT PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['!Якутск', 'Адыгея', 'Балашиха', 'Волжский', 'Вологда', 'Воронеж',\n",
       "       'Выездная', 'Жуковский', 'Интернет-магазин', 'Казань', 'Калуга',\n",
       "       'Коломна', 'Красноярск', 'Курск', 'Москва', 'Мытищи', 'Н.Новгород',\n",
       "       'Новосибирск', 'Омск', 'РостовНаДону', 'СПб', 'Самара', 'Сергиев',\n",
       "       'Сургут', 'Томск', 'Тюмень', 'Уфа', 'Химки', 'Цифровой', 'Чехов',\n",
       "       'Якутск', 'Ярославль'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#Let's check first part of shop_name\n",
    "shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\n",
    "shops['city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#First part of shop_name is city name, except for 'Интернет-магазин'\n",
    "#However, some city names are not properly-written. Let's fix them before label-encoding city names\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "shops.loc[shops['shop_name'] == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\n",
    "shops.loc[shops['city'] == '!Якутск', 'city'] = 'Якутск'\n",
    "shops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n",
    "shops = shops[['shop_id','city_code']]\n",
    "\n",
    "cats['split'] = cats['item_category_name'].str.split('-')\n",
    "cats['type'] = cats['split'].map(lambda x: x[0].strip())\n",
    "cats['type_code'] = LabelEncoder().fit_transform(cats['type'])\n",
    "#If subtype is nan then type\n",
    "cats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "cats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\n",
    "cats = cats[['item_category_id','type_code', 'subtype_code']]\n",
    "\n",
    "items.drop(['item_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of shops is 42 & no. of unique items is 5100.\n"
     ]
    }
   ],
   "source": [
    "#DATA LEAK\n",
    "print('No. of shops is {} & no. of unique items is {}.'.format(test['shop_id'].nunique(),test['item_id'].nunique()))\n",
    "assert len(test) == test['shop_id'].nunique() * test['item_id'].nunique()\n",
    "#Interestingly, test set includes item pairs for every shop. However, train set only contains sold or returned items.\n",
    "#We need to replicate these pairs in the train set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LEAK\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "matrix = []\n",
    "cols = ['date_block_num','shop_id','item_id']\n",
    "for i in range(34):\n",
    "    leak_train_filtered = leak_train[leak_train['date_block_num'] == i]\n",
    "    matrix.append(np.array(list(product([i], leak_train_filtered['shop_id'].unique(), leak_train_filtered['item_id'].unique())), dtype='int16'))\n",
    "    \n",
    "matrix = pd.DataFrame(np.vstack(matrix), columns=cols)\n",
    "matrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\n",
    "matrix['shop_id'] = matrix['shop_id'].astype(np.int8)\n",
    "matrix['item_id'] = matrix['item_id'].astype(np.int16)\n",
    "matrix.sort_values(cols,inplace=True)\n",
    "\n",
    "group = leak_train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\n",
    "group.columns = ['item_cnt_month']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(matrix, group, on=cols, how='left')\n",
    "main_combined['item_cnt_month'] = (main_combined['item_cnt_month'].fillna(0).clip(0,20).astype(np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#Required for feature engineering\n",
    "#To check if this is correct\n",
    "leak_train['revenue'] = leak_train['item_price'] *  leak_train['item_cnt_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#Note that summing up item_cnt_month will return infinite since it exceeds maximum range\n",
    "np.sum(main_combined['item_cnt_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#We do the same for test\n",
    "test['date_block_num'] = 34\n",
    "test['date_block_num'] = test['date_block_num'].astype(np.int8)\n",
    "test['shop_id'] = test['shop_id'].astype(np.int8)\n",
    "test['item_id'] = test['item_id'].astype(np.int16)\n",
    "\n",
    "main_combined = pd.concat([main_combined, test], sort=False,ignore_index=True, keys=cols)\n",
    "main_combined.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE \n",
    "main_combined = pd.merge(main_combined, shops, on=['shop_id'], how='left')\n",
    "main_combined = pd.merge(main_combined, items, on=['item_id'], how='left')\n",
    "main_combined = pd.merge(main_combined, cats, on=['item_category_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>ID</th>\n",
       "      <th>city_code</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>type_code</th>\n",
       "      <th>subtype_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id  item_cnt_month   ID  city_code  \\\n",
       "0               0        2       19             0.0  0.0          0   \n",
       "1               0        2       27             1.0  0.0          0   \n",
       "2               0        2       28             0.0  0.0          0   \n",
       "3               0        2       29             0.0  0.0          0   \n",
       "4               0        2       32             0.0  0.0          0   \n",
       "\n",
       "   item_category_id  type_code  subtype_code  \n",
       "0                40         11             4  \n",
       "1                19          5            10  \n",
       "2                30          8            55  \n",
       "3                23          5            16  \n",
       "4                40         11             4  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS [FOR ORIGINAL DATASET]\n",
    "#BASIC STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "main = leak_train\n",
    "main.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Features unique values\n",
    "for col in main.columns:\n",
    "    print(\"Number of unique values of {} : {}\".format(col, main[col].nunique()))    \n",
    "#This data is over 34 months\n",
    "#There are 42 different shops, 12 are redundant\n",
    "#Many different item_ids, many repetitions\n",
    "#Many different item_prices. However, unique values is higher than that of item_id. This shows that many items have different prices over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#SALES/TRANSACTIONS TRENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Lets view the trend of item_cnt,mean_item_cnt,transactions over time\n",
    "#We begin by importing matplotlib\n",
    "ts = main.groupby('date_block_num')['item_cnt_day'].sum()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(311)\n",
    "plt.title('item_cnt over months')\n",
    "plt.xlabel('month')\n",
    "plt.ylabel('item_cnt')\n",
    "plt.plot(ts)\n",
    "\n",
    "ts = main.groupby('date_block_num')['item_cnt_day'].mean()\n",
    "plt.subplot(312)\n",
    "plt.title('mean_item_cnt over months')\n",
    "plt.xlabel('month')\n",
    "plt.ylabel('mean_item_cnt')\n",
    "plt.plot(ts)\n",
    "plt.plot()\n",
    "\n",
    "ts = main.groupby('date_block_num')['date_block_num'].count()\n",
    "plt.subplot(313)\n",
    "plt.title('transactions over months')\n",
    "plt.xlabel('month')\n",
    "plt.ylabel('transactions')\n",
    "plt.plot(ts)\n",
    "plt.plot()\n",
    "\n",
    "#We observe 2 \"spikes\" in the data. They seem to be located at end of each year, implying seasonality/year effects\n",
    "#Increasing trend for item_cnt & transactions\n",
    "#Decreasing trend for mean_item_cnt, possibly due to addition of 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Let's view the distribution of item_cnt,mean_item_cnt & transactions \n",
    "#We begin by importing seaborn\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(311)\n",
    "plt.title('item_cnt distribution')\n",
    "plt.xlabel('item_cnt')\n",
    "plt.ylabel('distribution')\n",
    "sns.distplot(main['item_cnt_day'], hist=False, kde=True, color = 'darkblue', hist_kws={'edgecolor':'black'},kde_kws={'linewidth': 4})\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.title('mean_item_cnt distribution')\n",
    "plt.xlabel('mean_item_cnt')\n",
    "plt.ylabel('distribution')\n",
    "sns.distplot(main.groupby('date_block_num')['item_cnt_day'].mean(), hist=False, kde=True, color = 'darkblue', hist_kws={'edgecolor':'black'},kde_kws={'linewidth': 4})\n",
    "plt.plot()\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.title('transactions distribution')\n",
    "plt.xlabel('transactions')\n",
    "plt.ylabel('distribution')\n",
    "sns.distplot(main.groupby('date_block_num')['item_cnt_day'].count(), hist=False, kde=True, color = 'darkblue', hist_kws={'edgecolor':'black'},kde_kws={'linewidth': 4})\n",
    "plt.plot()\n",
    "\n",
    "#Data seems to be left-skewed, with most item sales averaging 1\n",
    "#There seems to have 2 \"bumps\" for transactions, corrsponding to that of transactions over months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Let's view the distribution of item_cnt BY shop_id\n",
    "plt.figure(figsize=(16,8))\n",
    "ts = main.groupby(['shop_id'],as_index=False)['item_cnt_day'].sum()\n",
    "plt.title('Sales by Shop')\n",
    "plt.bar(range(len(ts['item_cnt_day'])),list(ts['item_cnt_day']), align='center')\n",
    "plt.xticks(range(len(ts['shop_id'])),list(ts['shop_id'].unique()))\n",
    "plt.ylabel('Sales')\n",
    "plt.show()\n",
    "#Interestingly, most sales come shop_id 31,25,28,42,57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#TIME SERIES STATIONARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Seems like seasonality is involved\n",
    "#We check using multiplcative model\n",
    "ts = main.groupby(['date_block_num'])['item_cnt_day'].sum()\n",
    "import statsmodels.api as sm\n",
    "res = sm.tsa.seasonal_decompose(ts.values,freq=12,model=\"multiplicative\")\n",
    "fig = res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Now we check usng additive model\n",
    "res = sm.tsa.seasonal_decompose(ts.values,freq=12,model=\"additive\")\n",
    "#plt.figure(figsize=(16,12))\n",
    "fig = res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#We create a function for de-trending\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "def difference(dataset,interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval,len(dataset)):\n",
    "        difference = dataset[i] - dataset[i-interval]\n",
    "        diff.append(difference)\n",
    "    return pd.Series(diff)\n",
    "\n",
    "#We create a function for checking stationarity\n",
    "def test_stationarity(timeseries):    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#We create a temp. sum of item_cnt_day for each month\n",
    "ts = main.groupby(['date_block_num'])['item_cnt_day'].sum()\n",
    "#Let's check stationarity for original summed data\n",
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Let's de-trend and print \n",
    "import matplotlib.pyplot as plt\n",
    "ts.astype('float')\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(311)\n",
    "plt.title('Original')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sales')\n",
    "plt.plot(ts)\n",
    "\n",
    "plt.subplot(312)\n",
    "ts_new = difference(ts)\n",
    "plt.title('After De-trend')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sales')\n",
    "plt.plot(ts_new)\n",
    "plt.plot()\n",
    "\n",
    "plt.subplot(313)\n",
    "ts_new = difference(ts,12)\n",
    "plt.title('After De-seasonalization')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sales')\n",
    "plt.plot(ts_new)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Let's check stationarity for de-seasonlised data\n",
    "test_stationarity(ts_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#OUTLIERS [item_cnt]\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.violinplot(x=main[\"item_cnt_day\"])\n",
    "#There seems to be some outliers, with most points = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#OUTLIERS [item_price]\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.violinplot(x=main[\"item_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#SHOPS\n",
    "shops['temp'] = shops['shop_name'].str.split(' ').map(lambda x: x[1])\n",
    "for i in shops['temp'].unique():\n",
    "    if shops[shops['temp'] == i]['shop_id'].nunique() > 1:\n",
    "        print(i)\n",
    "#These are the shops with similar names    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Among these, these 3 are the same:\n",
    "#'!Якутск Орджоникидзе, 56 фран' & 'Якутск Орджоникидзе, 56'\n",
    "shops[shops['temp'] == 'Орджоникидзе,']['shop_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Getting their shop_id:\n",
    "shops[shops['shop_name'].isin(['!Якутск Орджоникидзе, 56 фран','Якутск Орджоникидзе, 56'])]['shop_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#'!Якутск ТЦ \"Центральный\" фран' & 'Якутск ТЦ \"Центральный\"'\n",
    "shops[shops['temp'] == 'ТЦ']['shop_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Getting their shop_id:\n",
    "shops[shops['shop_name'].isin(['!Якутск ТЦ \"Центральный\" фран' ,'Якутск ТЦ \"Центральный\"'])]['shop_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#'Жуковский ул. Чкалова 39м?' & 'Жуковский ул. Чкалова 39м²'\n",
    "shops[shops['temp'] == 'ул.']['shop_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Getting their shop_id:\n",
    "shops[shops['shop_name'].isin([ 'Жуковский ул. Чкалова 39м?','Жуковский ул. Чкалова 39м²'])]['shop_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>ID</th>\n",
       "      <th>city_code</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>type_code</th>\n",
       "      <th>subtype_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id  item_cnt_month   ID  city_code  \\\n",
       "0               0        2       19             0.0  0.0          0   \n",
       "1               0        2       27             1.0  0.0          0   \n",
       "2               0        2       28             0.0  0.0          0   \n",
       "3               0        2       29             0.0  0.0          0   \n",
       "4               0        2       32             0.0  0.0          0   \n",
       "\n",
       "   item_category_id  type_code  subtype_code  \n",
       "0                40         11             4  \n",
       "1                19          5            10  \n",
       "2                30          8            55  \n",
       "3                23          5            16  \n",
       "4                40         11             4  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#TARGET LAG\n",
    "#Using it as lag feature\n",
    "#We use lags=3 for now\n",
    "lag = main_combined[['date_block_num','shop_id','item_id', 'item_cnt_month']].copy()\n",
    "for i in range(1,4):\n",
    "    lag.columns = ['date_block_num','shop_id','item_id', 'item_cnt_month_lag_'+str(i)]\n",
    "    lag['date_block_num'] += 1\n",
    "    main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "#Drop date_avg_item_cnt\n",
    "main_combined['item_cnt_month_lag_1'].fillna(0, inplace=True) \n",
    "main_combined['item_cnt_month_lag_2'].fillna(0, inplace=True) \n",
    "main_combined['item_cnt_month_lag_3'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>ID</th>\n",
       "      <th>city_code</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>type_code</th>\n",
       "      <th>subtype_code</th>\n",
       "      <th>item_cnt_month_lag_1</th>\n",
       "      <th>item_cnt_month_lag_2</th>\n",
       "      <th>item_cnt_month_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id  item_cnt_month   ID  city_code  \\\n",
       "0               0        2       19             0.0  0.0          0   \n",
       "1               0        2       27             1.0  0.0          0   \n",
       "2               0        2       28             0.0  0.0          0   \n",
       "3               0        2       29             0.0  0.0          0   \n",
       "4               0        2       32             0.0  0.0          0   \n",
       "\n",
       "   item_category_id  type_code  subtype_code  item_cnt_month_lag_1  \\\n",
       "0                40         11             4                   0.0   \n",
       "1                19          5            10                   0.0   \n",
       "2                30          8            55                   0.0   \n",
       "3                23          5            16                   0.0   \n",
       "4                40         11             4                   0.0   \n",
       "\n",
       "   item_cnt_month_lag_2  item_cnt_month_lag_3  \n",
       "0                   0.0                   0.0  \n",
       "1                   0.0                   0.0  \n",
       "2                   0.0                   0.0  \n",
       "3                   0.0                   0.0  \n",
       "4                   0.0                   0.0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#MEANS ENCODING\n",
    "main_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrCoef of date_block_num is -0.12542882046287424\n",
      "CorrCoef of shop_id is -0.038236993745493816\n",
      "CorrCoef of item_id is -0.034179936467631185\n",
      "CorrCoef of item_cnt_month is -0.33234702564419827\n",
      "CorrCoef of ID is -0.0006851326304700594\n",
      "CorrCoef of city_code is -0.21192333012714562\n",
      "CorrCoef of item_category_id is -0.05808623677139237\n",
      "CorrCoef of type_code is -0.03080432593441126\n",
      "CorrCoef of subtype_code is -0.07069833783259137\n",
      "CorrCoef of item_cnt_month_lag_1 is -0.3432719115811627\n",
      "CorrCoef of item_cnt_month_lag_2 is -0.34857178630103164\n",
      "CorrCoef of item_cnt_month_lag_3 is -0.34676890269293964\n"
     ]
    }
   ],
   "source": [
    "#FEATURE ENGINEERING [DO NOT RUN]\n",
    "#SELECTING VARIABLES [1st Level]\n",
    "from itertools import combinations\n",
    "for i in main_combined.columns:\n",
    "    mean = main_combined.groupby([i]).agg({'item_cnt_month': ['mean']})\n",
    "    mean.columns = ['avg_item_cnt']\n",
    "    mean.reset_index(inplace=True)\n",
    "    print(\"CorrCoef of {} is {}\".format(i,mean['avg_item_cnt'].corr(main_combined['item_cnt_month'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrCoef of date_block_num and shop_id is 0.006675314799036736\n",
      "CorrCoef of date_block_num and item_id is 0.009519247460112854\n",
      "CorrCoef of date_block_num and item_cnt_month is 0.00807134414197245\n",
      "CorrCoef of date_block_num and ID is -0.0033941463376048597\n",
      "CorrCoef of date_block_num and city_code is 0.02532686794124232\n",
      "CorrCoef of date_block_num and item_category_id is 0.0066839143002622526\n",
      "CorrCoef of date_block_num and type_code is -0.022673341642333793\n",
      "CorrCoef of date_block_num and subtype_code is 0.019765925363616595\n",
      "CorrCoef of date_block_num and item_cnt_month_lag_1 is -0.01419447249748323\n",
      "CorrCoef of date_block_num and item_cnt_month_lag_2 is -0.006266204140742783\n",
      "CorrCoef of date_block_num and item_cnt_month_lag_3 is 0.0012720640258968628\n",
      "CorrCoef of shop_id and item_id is 0.0016969723207861445\n",
      "CorrCoef of shop_id and item_cnt_month is -0.009902508367535772\n",
      "CorrCoef of shop_id and ID is 0.0033472504854204616\n",
      "CorrCoef of shop_id and city_code is -0.038236993745493816\n",
      "CorrCoef of shop_id and item_category_id is 0.0452624355945622\n",
      "CorrCoef of shop_id and type_code is 0.03217933616814109\n",
      "CorrCoef of shop_id and subtype_code is -0.01744641170819947\n",
      "CorrCoef of shop_id and item_cnt_month_lag_1 is 0.0006873328498976822\n",
      "CorrCoef of shop_id and item_cnt_month_lag_2 is 0.009857896361543574\n",
      "CorrCoef of shop_id and item_cnt_month_lag_3 is 0.0049159115328928985\n",
      "CorrCoef of item_id and item_cnt_month is -0.0004580409290290817\n",
      "CorrCoef of item_id and ID is -0.0008711676329532664\n",
      "CorrCoef of item_id and city_code is -0.004472058640302314\n",
      "CorrCoef of item_id and item_category_id is -0.034179936467631185\n",
      "CorrCoef of item_id and type_code is -0.034179936467631185\n",
      "CorrCoef of item_id and subtype_code is -0.034179936467631185\n",
      "CorrCoef of item_id and item_cnt_month_lag_1 is -0.018420648976792995\n",
      "CorrCoef of item_id and item_cnt_month_lag_2 is 0.004161342357605062\n",
      "CorrCoef of item_id and item_cnt_month_lag_3 is -0.004988335370945991\n",
      "CorrCoef of item_cnt_month and ID is -0.0013538791004548926\n",
      "CorrCoef of item_cnt_month and city_code is -0.1365212241905845\n",
      "CorrCoef of item_cnt_month and item_category_id is -0.0839711631173609\n",
      "CorrCoef of item_cnt_month and type_code is 0.01497073492718089\n",
      "CorrCoef of item_cnt_month and subtype_code is -0.11944566620852103\n",
      "CorrCoef of item_cnt_month and item_cnt_month_lag_1 is -0.09829548604483146\n",
      "CorrCoef of item_cnt_month and item_cnt_month_lag_2 is -0.09829548604483146\n",
      "CorrCoef of item_cnt_month and item_cnt_month_lag_3 is -0.09829548604483146\n",
      "CorrCoef of ID and city_code is -0.0032433676480805177\n",
      "CorrCoef of ID and item_category_id is -0.0018200538386005398\n",
      "CorrCoef of ID and type_code is -0.0014526813171539346\n",
      "CorrCoef of ID and subtype_code is -0.0013832504908496462\n",
      "CorrCoef of ID and item_cnt_month_lag_1 is -0.002688201413781294\n",
      "CorrCoef of ID and item_cnt_month_lag_2 is -0.002704103910716329\n",
      "CorrCoef of ID and item_cnt_month_lag_3 is -0.0027134215636303244\n",
      "CorrCoef of city_code and item_category_id is -0.011784422453147326\n",
      "CorrCoef of city_code and type_code is -0.004391576403135111\n",
      "CorrCoef of city_code and subtype_code is 0.0028636017738740043\n",
      "CorrCoef of city_code and item_cnt_month_lag_1 is -0.01915086580621433\n",
      "CorrCoef of city_code and item_cnt_month_lag_2 is -0.010499585599163894\n",
      "CorrCoef of city_code and item_cnt_month_lag_3 is -0.009350965616832286\n",
      "CorrCoef of item_category_id and type_code is -0.05808623677139237\n",
      "CorrCoef of item_category_id and subtype_code is -0.05808623677139237\n",
      "CorrCoef of item_category_id and item_cnt_month_lag_1 is -0.04631226603856778\n",
      "CorrCoef of item_category_id and item_cnt_month_lag_2 is -0.05305003450865343\n",
      "CorrCoef of item_category_id and item_cnt_month_lag_3 is -0.05978581143313777\n",
      "CorrCoef of type_code and subtype_code is 0.3942125707754291\n",
      "CorrCoef of type_code and item_cnt_month_lag_1 is -0.02971770699666812\n",
      "CorrCoef of type_code and item_cnt_month_lag_2 is -0.02582604482253598\n",
      "CorrCoef of type_code and item_cnt_month_lag_3 is -0.010992711050065405\n",
      "CorrCoef of subtype_code and item_cnt_month_lag_1 is 0.0016663442068369427\n",
      "CorrCoef of subtype_code and item_cnt_month_lag_2 is -0.05410997831270372\n",
      "CorrCoef of subtype_code and item_cnt_month_lag_3 is -0.011426915225017384\n",
      "CorrCoef of item_cnt_month_lag_1 and item_cnt_month_lag_2 is -0.07109943608131679\n",
      "CorrCoef of item_cnt_month_lag_1 and item_cnt_month_lag_3 is -0.06461017589365815\n",
      "CorrCoef of item_cnt_month_lag_2 and item_cnt_month_lag_3 is -0.05646465683490475\n"
     ]
    }
   ],
   "source": [
    "#FEATURE ENGINEERING [DO NOT RUN]\n",
    "#SELECTING VARIABLES [2nd Level]\n",
    "for i in combinations(main_combined.columns,2):\n",
    "    mean = main_combined.groupby([i[0],i[1]]).agg({'item_cnt_month': ['mean']})\n",
    "    mean.columns = ['avg_item_cnt']\n",
    "    mean.reset_index(inplace=True)\n",
    "    print(\"CorrCoef of {} and {} is {}\".format(i[0],i[1],mean['avg_item_cnt'].corr(main_combined['item_cnt_month'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-0e968dec1f2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#FEATURE ENGINEERING\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#SELECTING VARIABLES [3rd Level]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcorr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_combined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_combined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'item_cnt_month'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "#FEATURE ENGINEERING [DO NOT RUN]\n",
    "#SELECTING VARIABLES [3rd Level]\n",
    "corr = train.corr()\n",
    "for i in combinations(main_combined.columns,3):\n",
    "    mean = main_combined.groupby([i[0],i[1],i[2]]).agg({'item_cnt_month': ['mean']})\n",
    "    mean.columns = ['avg_item_cnt']\n",
    "    mean.reset_index(inplace=True)\n",
    "    print(\"CorrCoef of {} , {} and {} is {}\".format(i[0],i[1],i[2],mean['avg_item_cnt'].corr(main_combined['item_cnt_month'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#We add mean item_cnt for each month as lag variable\n",
    "group = main_combined.groupby(['date_block_num']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num'], how='left')\n",
    "main_combined['date_avg_item_cnt'] = main_combined['date_avg_item_cnt'].astype(np.float16)\n",
    "\n",
    "#Using it as lag feature\n",
    "lag = main_combined[['date_block_num','shop_id','item_id', 'date_avg_item_cnt']].copy()\n",
    "lag.columns = ['date_block_num','shop_id','item_id', 'date_avg_item_lag_1']\n",
    "lag['date_block_num'] += 1\n",
    "main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "#Drop date_avg_item_cnt\n",
    "main_combined.drop(['date_avg_item_cnt'], axis=1, inplace=True)\n",
    "main_combined['date_avg_item_lag_1'].fillna(0, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#We add mean item_cnt for each item_id for each month as lag variable\n",
    "#We use 3 lags since their correlations with date_item_avg_item_cnt are the strongest\n",
    "group = main_combined.groupby(['date_block_num','item_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_item_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num','item_id'], how='left')\n",
    "main_combined['date_item_avg_item_cnt'] = main_combined['date_item_avg_item_cnt'].astype(np.float16)\n",
    "\n",
    "#Using it as lag feature\n",
    "lag = main_combined[['date_block_num','shop_id','item_id', 'date_item_avg_item_cnt']].copy()\n",
    "lis = [1,2,3,6,12]\n",
    "for i in lis:\n",
    "    lag.columns = ['date_block_num','shop_id','item_id', 'date_item_avg_item_lag_'+str(i)]\n",
    "    lag['date_block_num'] += 1\n",
    "    main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "#Drop date_avg_item_cnt\n",
    "main_combined.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)\n",
    "main_combined['date_item_avg_item_lag_1'].fillna(0, inplace=True) \n",
    "main_combined['date_item_avg_item_lag_2'].fillna(0, inplace=True) \n",
    "main_combined['date_item_avg_item_lag_3'].fillna(0, inplace=True) \n",
    "main_combined['date_item_avg_item_lag_6'].fillna(0, inplace=True) \n",
    "main_combined['date_item_avg_item_lag_12'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#We add mean item_cnt for each shop_id for each month as lag variable\n",
    "#Seems like many lags have strong correlation with date_shop_avg_item_cnt\n",
    "#We shall use 3 lags for now\n",
    "group = main_combined.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num','shop_id'], how='left')\n",
    "\n",
    "#Using it as lag feature\n",
    "lis = [1,2,3,6,12]\n",
    "lag = main_combined[['date_block_num','shop_id','item_id', 'date_shop_avg_item_cnt']].copy()\n",
    "for i in lis:\n",
    "    lag.columns = ['date_block_num','shop_id','item_id', 'date_shop_avg_item_lag_'+str(i)]\n",
    "    lag['date_block_num'] += 1\n",
    "    main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "#Drop date_avg_item_cnt\n",
    "main_combined.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)\n",
    "main_combined['date_shop_avg_item_lag_1'].fillna(0, inplace=True) \n",
    "main_combined['date_shop_avg_item_lag_2'].fillna(0, inplace=True) \n",
    "main_combined['date_shop_avg_item_lag_3'].fillna(0, inplace=True) \n",
    "main_combined['date_shop_avg_item_lag_6'].fillna(0, inplace=True) \n",
    "main_combined['date_shop_avg_item_lag_12'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING \n",
    "#We add mean item_cnt for each item_category_id as lag variable\n",
    "group = main_combined.groupby(['date_block_num','item_category_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_item_category_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num','item_category_id'], how='left')\n",
    "main_combined['date_item_category_avg_item_cnt'] = main_combined['date_item_category_avg_item_cnt'].astype(np.float16)\n",
    "\n",
    "#Using it as lag feature\n",
    "lis = [1,2,3,6,12]\n",
    "lag = main_combined[['date_block_num','shop_id','item_id','date_item_category_avg_item_cnt']].copy()\n",
    "for i in lis:\n",
    "    lag.columns = ['date_block_num','shop_id','item_id','date_item_category_avg_item_lag_'+str(i)]\n",
    "    lag['date_block_num'] += 1\n",
    "    main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "#Drop date_avg_item_cnt\n",
    "main_combined.drop(['date_item_category_avg_item_cnt'], axis=1, inplace=True)\n",
    "main_combined['date_item_category_avg_item_lag_1'].fillna(0, inplace=True) \n",
    "main_combined['date_item_category_avg_item_lag_2'].fillna(0, inplace=True) \n",
    "main_combined['date_item_category_avg_item_lag_3'].fillna(0, inplace=True) \n",
    "main_combined['date_item_category_avg_item_lag_6'].fillna(0, inplace=True) \n",
    "main_combined['date_item_category_avg_item_lag_12'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING \n",
    "#We add mean item_cnt for each city_code for each month\n",
    "group = main_combined.groupby(['date_block_num', 'city_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_city_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num', 'city_code'], how='left')\n",
    "\n",
    "#Using it as lag feature\n",
    "lag = main_combined[['date_block_num','shop_id','item_id','date_city_avg_item_cnt']].copy()\n",
    "for i in range(1,2):\n",
    "    lag.columns = ['date_block_num','shop_id','item_id','date_city_avg_item_lag_'+str(i)]\n",
    "    lag['date_block_num'] += 1\n",
    "    main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "#Drop date_avg_item_cnt\n",
    "main_combined.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)\n",
    "main_combined['date_city_avg_item_lag_1'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING \n",
    "#We add mean item_cnt for each type_code\n",
    "group = main_combined.groupby(['date_block_num', 'type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_type_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num', 'type_code'], how='left')\n",
    "\n",
    "#Using it as lag feature\n",
    "lag = main_combined[['date_block_num','shop_id','item_id','date_type_avg_item_cnt']].copy()\n",
    "for i in range(1,2):\n",
    "    lag.columns = ['date_block_num','shop_id','item_id','date_type_avg_item_lag_'+str(i)]\n",
    "    lag['date_block_num'] += 1\n",
    "    main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "#Drop date_avg_item_cnt\n",
    "main_combined.drop(['date_type_avg_item_cnt'], axis=1, inplace=True)\n",
    "main_combined['date_type_avg_item_lag_1'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING \n",
    "#We add mean item_cnt for each subtype_code\n",
    "group = main_combined.groupby(['date_block_num', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_subtype_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num', 'subtype_code'], how='left')\n",
    "\n",
    "#Using it as lag feature\n",
    "lag = main_combined[['date_block_num','shop_id','item_id','date_subtype_avg_item_cnt']].copy()\n",
    "for i in range(1,2):\n",
    "    lag.columns = ['date_block_num','shop_id','item_id','date_subtype_avg_item_lag_'+str(i)]\n",
    "    lag['date_block_num'] += 1\n",
    "    main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "#Drop date_avg_item_cnt\n",
    "main_combined.drop(['date_subtype_avg_item_cnt'], axis=1, inplace=True)\n",
    "main_combined['date_subtype_avg_item_lag_1'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#We add mean item_cnt for each item_category_id as lag variable\n",
    "group = main_combined.groupby(['date_block_num', 'shop_id', 'item_category_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_cat_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num','shop_id', 'item_category_id'], how='left')\n",
    "\n",
    "#Using it as lag feature\n",
    "lag = main_combined[['date_block_num','shop_id','item_id','date_shop_cat_avg_item_cnt']].copy()\n",
    "for i in range(1,2):\n",
    "    lag.columns = ['date_block_num','shop_id','item_id','date_shop_cat_avg_item_lag_'+str(i)]\n",
    "    lag['date_block_num'] += 1\n",
    "    main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "#Drop date_avg_item_cnt\n",
    "main_combined.drop(['date_shop_cat_avg_item_cnt'], axis=1, inplace=True)\n",
    "main_combined['date_shop_cat_avg_item_lag_1'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING \n",
    "#We add mean item_cnt for each shop_id for each type_code\n",
    "group = main_combined.groupby(['date_block_num', 'shop_id', 'type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_type_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num','shop_id', 'type_code'], how='left')\n",
    "\n",
    "#Using it as lag feature\n",
    "lag = main_combined[['date_block_num','shop_id','item_id','date_shop_type_avg_item_cnt']].copy()\n",
    "for i in range(1,2):\n",
    "    lag.columns = ['date_block_num','shop_id','item_id','date_shop_type_avg_item_lag_'+str(i)]\n",
    "    lag['date_block_num'] += 1\n",
    "    main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "#Drop date_avg_item_cnt\n",
    "main_combined.drop(['date_shop_type_avg_item_cnt'], axis=1, inplace=True)\n",
    "main_combined['date_shop_type_avg_item_lag_1'].fillna(0, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING \n",
    "#We add mean item_cnt for each shop_id for each subtype_code for each month\n",
    "group = main_combined.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_subtype_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\n",
    "\n",
    "#Using it as lag feature\n",
    "lag = main_combined[['date_block_num','shop_id','item_id','date_shop_subtype_avg_item_cnt']].copy()\n",
    "for i in range(1,2):\n",
    "    lag.columns = ['date_block_num','shop_id','item_id','date_shop_subtype_avg_item_lag_'+str(i)]\n",
    "    lag['date_block_num'] += 1\n",
    "    main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "#Drop date_avg_item_cnt\n",
    "main_combined.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)\n",
    "main_combined['date_shop_subtype_avg_item_lag_1'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING \n",
    "#We add mean item_cnt for each item_id for each city_code\n",
    "group = main_combined.groupby(['date_block_num', 'item_id', 'city_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_item_city_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num', 'item_id','city_code'], how='left')\n",
    "\n",
    "#Using it as lag feature\n",
    "lag = main_combined[['date_block_num','shop_id','item_id','date_item_city_avg_item_cnt']].copy()\n",
    "for i in range(1,2):\n",
    "    lag.columns = ['date_block_num','shop_id','item_id','date_item_city_avg_item_lag_'+str(i)]\n",
    "    lag['date_block_num'] += 1\n",
    "    main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "#Drop date_avg_item_cnt\n",
    "main_combined.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)\n",
    "main_combined['date_item_city_avg_item_lag_1'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#TRENDS\n",
    "#We create 6 lags & select the latest lag that is not null as trend\n",
    "#For each item_id\n",
    "group = leak_train.groupby(['item_id']).agg({'item_price': ['mean']})\n",
    "group.columns = ['item_avg_item_price']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(main_combined, group, on=['item_id'], how='left')\n",
    "main_combined['item_avg_item_price'] = main_combined['item_avg_item_price'].astype(np.float16)\n",
    "\n",
    "group = leak_train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\n",
    "group.columns = ['date_item_avg_item_price']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "#For each month, for each item_id\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num','item_id'], how='left')\n",
    "main_combined['date_item_avg_item_price'] = main_combined['date_item_avg_item_price'].astype(np.float16)\n",
    "\n",
    "lags = [1,2,3,4,5,6]\n",
    "for i in range(1,7):\n",
    "    lag.columns = ['date_block_num','shop_id','item_id','date_item_avg_item_price_lag_'+str(i)]\n",
    "    lag['date_block_num'] += 1\n",
    "    main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "for i in lags:\n",
    "    main_combined['delta_price_lag_'+str(i)] = \\\n",
    "        (main_combined['date_item_avg_item_price_lag_'+str(i)] - main_combined['item_avg_item_price']) / main_combined['item_avg_item_price']\n",
    "\n",
    "def select_trend(row):\n",
    "    for i in lags:\n",
    "        if row['delta_price_lag_'+str(i)]:\n",
    "            return row['delta_price_lag_'+str(i)]\n",
    "    return 0\n",
    "    \n",
    "main_combined['delta_price_lag'] = main_combined.apply(select_trend, axis=1)\n",
    "main_combined['delta_price_lag'] = main_combined['delta_price_lag'].astype(np.float16)\n",
    "main_combined['delta_price_lag'].fillna(0, inplace=True)\n",
    "\n",
    "fetures_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\n",
    "for i in lags:\n",
    "    fetures_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n",
    "    fetures_to_drop += ['delta_price_lag_'+str(i)]\n",
    "\n",
    "main_combined.drop(fetures_to_drop, axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#TRENDS\n",
    "#For each month, each shop_id's revenue\n",
    "group = leak_train.groupby(['date_block_num','shop_id']).agg({'revenue': ['sum']})\n",
    "group.columns = ['date_shop_revenue']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(main_combined, group, on=['date_block_num','shop_id'], how='left')\n",
    "main_combined['date_shop_revenue'] = main_combined['date_shop_revenue'].astype(np.float32)\n",
    "\n",
    "#For each shop_id's revenue\n",
    "group = group.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\n",
    "group.columns = ['shop_avg_revenue']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "main_combined = pd.merge(main_combined, group, on=['shop_id'], how='left')\n",
    "main_combined['shop_avg_revenue'] = main_combined['shop_avg_revenue'].astype(np.float32)\n",
    "\n",
    "main_combined['delta_revenue'] = (main_combined['date_shop_revenue'] - main_combined['shop_avg_revenue']) / main_combined['shop_avg_revenue']\n",
    "main_combined['delta_revenue'] = main_combined['delta_revenue'].astype(np.float16)\n",
    "\n",
    "lag.columns = ['date_block_num','shop_id','item_id','delta_revenue_lag_1']\n",
    "lag['date_block_num'] += 1\n",
    "main_combined = pd.merge(main_combined, lag, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "main_combined.drop(['date_shop_revenue','shop_avg_revenue','delta_revenue'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_combined['delta_revenue_lag_1'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#SPECIAL\n",
    "#Add months & no. of days for each month\n",
    "main_combined['month'] = main_combined['date_block_num'] % 12\n",
    "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "main_combined['days'] = main_combined['month'].map(days).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#SPECIAL\n",
    "#Months since the last sale for each shop/item pair and for item only\n",
    "cache = {}\n",
    "main_combined['item_shop_last_sale'] = -1\n",
    "main_combined['item_shop_last_sale'] = main_combined['item_shop_last_sale'].astype(np.int8)\n",
    "for idx, row in main_combined.iterrows():    \n",
    "    key = str(row.item_id)+' '+str(row.shop_id)\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        main_combined.at[idx, 'item_shop_last_sale'] = row.date_block_num - last_date_block_num\n",
    "        cache[key] = row.date_block_num   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#SPECIAL\n",
    "cache = {}\n",
    "main_combined['item_last_sale'] = -1\n",
    "main_combined['item_last_sale'] = main_combined['item_last_sale'].astype(np.int8)\n",
    "for idx, row in main_combined.iterrows():    \n",
    "    key = row.item_id\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        if row.date_block_num>last_date_block_num:\n",
    "            main_combined.at[idx, 'item_last_sale'] = row.date_block_num - last_date_block_num\n",
    "            cache[key] = row.date_block_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#SPECIAL\n",
    "main_combined['item_shop_first_sale'] = main_combined['date_block_num'] - main_combined.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\n",
    "main_combined['item_first_sale'] = main_combined['date_block_num'] - main_combined.groupby('item_id')['date_block_num'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>ID</th>\n",
       "      <th>city_code</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>type_code</th>\n",
       "      <th>subtype_code</th>\n",
       "      <th>item_cnt_month_lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>date_shop_subtype_avg_item_lag_1</th>\n",
       "      <th>date_item_city_avg_item_lag_1</th>\n",
       "      <th>delta_price_lag</th>\n",
       "      <th>delta_revenue_lag_1</th>\n",
       "      <th>month</th>\n",
       "      <th>days</th>\n",
       "      <th>item_shop_last_sale</th>\n",
       "      <th>item_last_sale</th>\n",
       "      <th>item_shop_first_sale</th>\n",
       "      <th>item_first_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id  item_cnt_month   ID  city_code  \\\n",
       "0               0        2       19             0.0  0.0          0   \n",
       "1               0        2       27             1.0  0.0          0   \n",
       "2               0        2       28             0.0  0.0          0   \n",
       "3               0        2       29             0.0  0.0          0   \n",
       "4               0        2       32             0.0  0.0          0   \n",
       "\n",
       "   item_category_id  type_code  subtype_code  item_cnt_month_lag_1  ...  \\\n",
       "0                40         11             4                   0.0  ...   \n",
       "1                19          5            10                   0.0  ...   \n",
       "2                30          8            55                   0.0  ...   \n",
       "3                23          5            16                   0.0  ...   \n",
       "4                40         11             4                   0.0  ...   \n",
       "\n",
       "   date_shop_subtype_avg_item_lag_1  date_item_city_avg_item_lag_1  \\\n",
       "0                               0.0                            0.0   \n",
       "1                               0.0                            0.0   \n",
       "2                               0.0                            0.0   \n",
       "3                               0.0                            0.0   \n",
       "4                               0.0                            0.0   \n",
       "\n",
       "   delta_price_lag  delta_revenue_lag_1  month  days  item_shop_last_sale  \\\n",
       "0              0.0                  0.0      0    31                   -1   \n",
       "1              0.0                  0.0      0    31                   -1   \n",
       "2              0.0                  0.0      0    31                   -1   \n",
       "3              0.0                  0.0      0    31                   -1   \n",
       "4              0.0                  0.0      0    31                   -1   \n",
       "\n",
       "   item_last_sale  item_shop_first_sale  item_first_sale  \n",
       "0              -1                     0                0  \n",
       "1              -1                     0                0  \n",
       "2              -1                     0                0  \n",
       "3              -1                     0                0  \n",
       "4              -1                     0                0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL PREP\n",
    "#Because of the using 12 as lag value drop first 12 months. Also drop all the columns with this month calculated values (other words which cannot be calcucated for the test set).\n",
    "main_combined = main_combined[main_combined['date_block_num'] > 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_block_num', 'shop_id', 'item_id', 'item_cnt_month', 'ID',\n",
       "       'city_code', 'item_category_id', 'type_code', 'subtype_code',\n",
       "       'item_cnt_month_lag_1', 'item_cnt_month_lag_2', 'item_cnt_month_lag_3',\n",
       "       'date_avg_item_lag_1', 'date_item_avg_item_lag_1',\n",
       "       'date_item_avg_item_lag_2', 'date_item_avg_item_lag_3',\n",
       "       'date_item_avg_item_lag_6', 'date_item_avg_item_lag_12',\n",
       "       'date_shop_avg_item_lag_1', 'date_shop_avg_item_lag_2',\n",
       "       'date_shop_avg_item_lag_3', 'date_shop_avg_item_lag_6',\n",
       "       'date_shop_avg_item_lag_12', 'date_item_category_avg_item_lag_1',\n",
       "       'date_item_category_avg_item_lag_2',\n",
       "       'date_item_category_avg_item_lag_3',\n",
       "       'date_item_category_avg_item_lag_6',\n",
       "       'date_item_category_avg_item_lag_12', 'date_city_avg_item_lag_1',\n",
       "       'date_type_avg_item_lag_1', 'date_subtype_avg_item_lag_1',\n",
       "       'date_shop_cat_avg_item_lag_1', 'date_shop_type_avg_item_lag_1',\n",
       "       'date_shop_subtype_avg_item_lag_1', 'date_item_city_avg_item_lag_1',\n",
       "       'delta_price_lag', 'delta_revenue_lag_1', 'month', 'days',\n",
       "       'item_shop_last_sale', 'item_last_sale', 'item_shop_first_sale',\n",
       "       'item_first_sale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6639294 entries, 4488710 to 11128003\n",
      "Data columns (total 43 columns):\n",
      "date_block_num                        int8\n",
      "shop_id                               int8\n",
      "item_id                               int16\n",
      "item_cnt_month                        float16\n",
      "ID                                    float64\n",
      "city_code                             int32\n",
      "item_category_id                      int64\n",
      "type_code                             int32\n",
      "subtype_code                          int32\n",
      "item_cnt_month_lag_1                  float16\n",
      "item_cnt_month_lag_2                  float16\n",
      "item_cnt_month_lag_3                  float16\n",
      "date_avg_item_lag_1                   float16\n",
      "date_item_avg_item_lag_1              float16\n",
      "date_item_avg_item_lag_2              float16\n",
      "date_item_avg_item_lag_3              float16\n",
      "date_item_avg_item_lag_6              float16\n",
      "date_item_avg_item_lag_12             float16\n",
      "date_shop_avg_item_lag_1              float16\n",
      "date_shop_avg_item_lag_2              float16\n",
      "date_shop_avg_item_lag_3              float16\n",
      "date_shop_avg_item_lag_6              float16\n",
      "date_shop_avg_item_lag_12             float16\n",
      "date_item_category_avg_item_lag_1     float16\n",
      "date_item_category_avg_item_lag_2     float16\n",
      "date_item_category_avg_item_lag_3     float16\n",
      "date_item_category_avg_item_lag_6     float16\n",
      "date_item_category_avg_item_lag_12    float16\n",
      "date_city_avg_item_lag_1              float16\n",
      "date_type_avg_item_lag_1              float16\n",
      "date_subtype_avg_item_lag_1           float16\n",
      "date_shop_cat_avg_item_lag_1          float16\n",
      "date_shop_type_avg_item_lag_1         float16\n",
      "date_shop_subtype_avg_item_lag_1      float16\n",
      "date_item_city_avg_item_lag_1         float16\n",
      "delta_price_lag                       float16\n",
      "delta_revenue_lag_1                   float16\n",
      "month                                 int8\n",
      "days                                  int8\n",
      "item_shop_last_sale                   int8\n",
      "item_last_sale                        int8\n",
      "item_shop_first_sale                  int8\n",
      "item_first_sale                       int8\n",
      "dtypes: float16(29), float64(1), int16(1), int32(3), int64(1), int8(8)\n",
      "memory usage: 658.5 MB\n"
     ]
    }
   ],
   "source": [
    "main_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN/VALIDATION SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN/VALIDATION SPLIT\n",
    "#HOLD-OUT\n",
    "#We skip first 12 months. Last month as validation.\n",
    "train_set = main_combined.query('date_block_num < 33').copy()\n",
    "validation_set = main_combined.query('date_block_num == 33').copy()\n",
    "\n",
    "# Create train and validation sets and labels. \n",
    "X_train = train_set.drop(['item_cnt_month'], axis=1)\n",
    "Y_train = train_set['item_cnt_month']\n",
    "X_validation = validation_set.drop(['item_cnt_month'], axis=1)\n",
    "Y_validation = validation_set['item_cnt_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "X_test = main_combined[main_combined['date_block_num'] == 34].drop(['item_cnt_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 0.754832\tvalid_1's rmse: 0.830805\n",
      "[2000]\ttraining's rmse: 0.724296\tvalid_1's rmse: 0.802792\n",
      "[3000]\ttraining's rmse: 0.705507\tvalid_1's rmse: 0.785674\n",
      "[4000]\ttraining's rmse: 0.691565\tvalid_1's rmse: 0.772002\n",
      "[5000]\ttraining's rmse: 0.679573\tvalid_1's rmse: 0.760195\n",
      "[6000]\ttraining's rmse: 0.669475\tvalid_1's rmse: 0.751294\n",
      "[7000]\ttraining's rmse: 0.66113\tvalid_1's rmse: 0.744065\n",
      "[8000]\ttraining's rmse: 0.653732\tvalid_1's rmse: 0.7381\n",
      "[9000]\ttraining's rmse: 0.645665\tvalid_1's rmse: 0.730689\n",
      "[10000]\ttraining's rmse: 0.639445\tvalid_1's rmse: 0.725206\n",
      "[11000]\ttraining's rmse: 0.633782\tvalid_1's rmse: 0.720468\n",
      "[12000]\ttraining's rmse: 0.628816\tvalid_1's rmse: 0.716151\n",
      "[13000]\ttraining's rmse: 0.624238\tvalid_1's rmse: 0.711865\n",
      "[14000]\ttraining's rmse: 0.619814\tvalid_1's rmse: 0.707945\n",
      "[15000]\ttraining's rmse: 0.615484\tvalid_1's rmse: 0.703977\n",
      "[16000]\ttraining's rmse: 0.611448\tvalid_1's rmse: 0.700718\n",
      "[17000]\ttraining's rmse: 0.607554\tvalid_1's rmse: 0.697048\n",
      "[18000]\ttraining's rmse: 0.603572\tvalid_1's rmse: 0.693898\n",
      "[19000]\ttraining's rmse: 0.599902\tvalid_1's rmse: 0.690321\n",
      "[20000]\ttraining's rmse: 0.596615\tvalid_1's rmse: 0.687247\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20000]\ttraining's rmse: 0.596615\tvalid_1's rmse: 0.687247\n",
      "Mean RMSE Val_Score is 0.686647663871641\n"
     ]
    }
   ],
   "source": [
    "#MODELLING\n",
    "#LGBM with HOLD-OUT\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from math import sqrt\n",
    "import lightgbm as lgb\n",
    "random_state = 0\n",
    "lgb_params = {\n",
    "    \"objective\" : \"regression\",\n",
    "    \"metric\" : \"rmse\",\n",
    "    \"boosting\": 'gbdt',\n",
    "    \"max_depth\" : -1,\n",
    "    \"num_leaves\" : 150,\n",
    "    \"num_threads\" : 8,\n",
    "    \"learning_rate\" : 0.01,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"bagging_fraction\" : 0.9,\n",
    "    \"feature_fraction\" : 0.3,\n",
    "    #\"min_data_in_leaf\": 80,\n",
    "    #\"min_sum_hessian_in_leaf\" : 10,\n",
    "    #\"tree_learner\": \"serial\",\n",
    "    #\"boost_from_average\": \"false\",\n",
    "    #\"lambda_l1\" : 5,\n",
    "    #\"lambda_l2\" : 5,\n",
    "    \"bagging_seed\" : random_state,\n",
    "    \"verbosity\" : 1,\n",
    "    \"seed\": random_state\n",
    "}\n",
    "\n",
    "input_train = X_train\n",
    "target_train = Y_train\n",
    "trn_data = lgb.Dataset(input_train, label=target_train)\n",
    "val_data = lgb.Dataset(X_validation, label=Y_validation)\n",
    "evals_result = {}\n",
    "lgb_clf = lgb.train(lgb_params,trn_data,20000,valid_sets = [trn_data, val_data],early_stopping_rounds=3000,verbose_eval = 1000,evals_result=evals_result)\n",
    "p_valid = lgb_clf.predict(X_validation).clip(0, 20)\n",
    "score_val = sqrt(mean_squared_error(Y_validation, p_valid))\n",
    "test_pred = lgb_clf.predict(X_test).clip(0, 20)    \n",
    "print(\"Mean RMSE Val_Score is {}\".format(score_val))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 81 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 6186922 is out of bounds for axis 0 with size 6186922",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\kwquan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\kwquan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\kwquan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\kwquan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\kwquan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\kwquan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 518, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n  File \"C:\\Users\\kwquan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 203, in _safe_split\n    X_subset = safe_indexing(X, indices)\n  File \"C:\\Users\\kwquan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 218, in safe_indexing\n    return X[indices]\n  File \"C:\\Users\\kwquan\\Anaconda3\\lib\\site-packages\\numpy\\core\\memmap.py\", line 331, in __getitem__\n    res = super(memmap, self).__getitem__(index)\nIndexError: index 6186922 is out of bounds for axis 0 with size 6186922\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-eb78b4193337>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgridParams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'MSE'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Run the grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best parameters found by grid search are:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 6186922 is out of bounds for axis 0 with size 6186922"
     ]
    }
   ],
   "source": [
    "#HYPERPARAMETER TUNING  [THIS PART CONTAINS ERROR, DO NOT RUN!]\n",
    "train_set = main_combined.query('date_block_num < 33').copy()\n",
    "validation_set = main_combined.query('date_block_num == 33').copy()\n",
    "# Create train and validation sets and labels. \n",
    "X_train = train_set.drop(['item_cnt_month'], axis=1).values\n",
    "Y_train = train_set['item_cnt_month'].values\n",
    "gridParams = {\n",
    "    'learning_rate': [0.01,0.009,0.008],\n",
    "    'num_leaves': [100,150,200],\n",
    "    'bagging_fraction' : [0.8,0.9,0.95],\n",
    "    'feature_fraction' : [0.3,0.4,0.5]\n",
    "}\n",
    "\n",
    "mdl = lgb.LGBMRegressor(boosting_type=lgb_params['boosting'], max_depth=lgb_params['max_depth'], n_estimators=20000, objective=lgb_params['objective'], random_state=random_state) \n",
    "\n",
    "lis = []\n",
    "lis.append(train_set.index.tolist())\n",
    "lis.append(validation_set.index.tolist())\n",
    "cv = [(lis[i] , lis[i+1])\n",
    "      for i in range(len(lis)-1)]\n",
    "\n",
    "scoring = {'MSE': 'neg_mean_squared_error'}\n",
    "grid = GridSearchCV(mdl, gridParams, verbose=1, cv=cv, scoring=scoring, n_jobs=-1, refit='MSE')\n",
    "# Run the grid\n",
    "grid.fit(X_train,Y_train)\n",
    "\n",
    "print('Best parameters found by grid search are:', grid.best_params_)\n",
    "print('Best score found by grid search is:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['date_block_num', 'shop_id', 'item_id', 'ID', 'city_code',\n",
       "       'item_category_id', 'type_code', 'subtype_code',\n",
       "       'item_cnt_month_lag_1', 'item_cnt_month_lag_2',\n",
       "       'item_cnt_month_lag_3', 'date_avg_item_lag_1',\n",
       "       'date_item_avg_item_lag_1', 'date_item_avg_item_lag_2',\n",
       "       'date_item_avg_item_lag_3', 'date_item_avg_item_lag_6',\n",
       "       'date_item_avg_item_lag_12', 'date_shop_avg_item_lag_1',\n",
       "       'date_shop_avg_item_lag_2', 'date_shop_avg_item_lag_3',\n",
       "       'date_shop_avg_item_lag_6', 'date_shop_avg_item_lag_12',\n",
       "       'date_item_category_avg_item_lag_1',\n",
       "       'date_item_category_avg_item_lag_2',\n",
       "       'date_item_category_avg_item_lag_3',\n",
       "       'date_item_category_avg_item_lag_6',\n",
       "       'date_item_category_avg_item_lag_12', 'date_city_avg_item_lag_1',\n",
       "       'date_type_avg_item_lag_1', 'date_subtype_avg_item_lag_1',\n",
       "       'date_shop_cat_avg_item_lag_1', 'date_shop_type_avg_item_lag_1',\n",
       "       'date_shop_subtype_avg_item_lag_1',\n",
       "       'date_item_city_avg_item_lag_1', 'delta_price_lag',\n",
       "       'delta_revenue_lag_1', 'month', 'days', 'item_shop_last_sale',\n",
       "       'item_last_sale', 'item_shop_first_sale', 'item_first_sale'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.813417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.368384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.347483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.935392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.227396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.643042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.543594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.192453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.808594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.934767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>3.391404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.143807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.160401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.749722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2.183471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2.998143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.056021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.191503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1.210197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.276078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.584665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.436206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1.864670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.627892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1.342196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.580037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.422517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.690084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1.085733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>4.562773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214170</th>\n",
       "      <td>214170</td>\n",
       "      <td>0.014722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214171</th>\n",
       "      <td>214171</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214172</th>\n",
       "      <td>214172</td>\n",
       "      <td>0.024767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214173</th>\n",
       "      <td>214173</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214174</th>\n",
       "      <td>214174</td>\n",
       "      <td>0.022054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214175</th>\n",
       "      <td>214175</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214176</th>\n",
       "      <td>214176</td>\n",
       "      <td>0.053593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214177</th>\n",
       "      <td>214177</td>\n",
       "      <td>0.018077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214178</th>\n",
       "      <td>214178</td>\n",
       "      <td>0.069392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214179</th>\n",
       "      <td>214179</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214180</th>\n",
       "      <td>214180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214181</th>\n",
       "      <td>214181</td>\n",
       "      <td>0.073648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214182</th>\n",
       "      <td>214182</td>\n",
       "      <td>0.048884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214183</th>\n",
       "      <td>214183</td>\n",
       "      <td>0.028534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214184</th>\n",
       "      <td>214184</td>\n",
       "      <td>0.010463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214185</th>\n",
       "      <td>214185</td>\n",
       "      <td>0.005024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214186</th>\n",
       "      <td>214186</td>\n",
       "      <td>0.033654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214187</th>\n",
       "      <td>214187</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214188</th>\n",
       "      <td>214188</td>\n",
       "      <td>0.017341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214189</th>\n",
       "      <td>214189</td>\n",
       "      <td>0.083648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214190</th>\n",
       "      <td>214190</td>\n",
       "      <td>0.032685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214191</th>\n",
       "      <td>214191</td>\n",
       "      <td>0.034964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214192</th>\n",
       "      <td>214192</td>\n",
       "      <td>0.056704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214193</th>\n",
       "      <td>214193</td>\n",
       "      <td>0.066949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214194</th>\n",
       "      <td>214194</td>\n",
       "      <td>0.013876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214195</th>\n",
       "      <td>214195</td>\n",
       "      <td>0.062951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214196</th>\n",
       "      <td>214196</td>\n",
       "      <td>0.032276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214197</th>\n",
       "      <td>214197</td>\n",
       "      <td>0.056092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214198</th>\n",
       "      <td>214198</td>\n",
       "      <td>0.011112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214199</th>\n",
       "      <td>214199</td>\n",
       "      <td>0.026709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  item_cnt_month\n",
       "0            0        0.813417\n",
       "1            1        1.368384\n",
       "2            2        1.347483\n",
       "3            3        0.935392\n",
       "4            4        0.227396\n",
       "5            5        0.643042\n",
       "6            6        0.543594\n",
       "7            7        0.192453\n",
       "8            8        0.808594\n",
       "9            9        0.934767\n",
       "10          10        3.391404\n",
       "11          11        0.143807\n",
       "12          12        0.160401\n",
       "13          13        0.749722\n",
       "14          14        2.183471\n",
       "15          15        2.998143\n",
       "16          16        0.056021\n",
       "17          17        0.191503\n",
       "18          18        1.210197\n",
       "19          19        0.276078\n",
       "20          20        0.584665\n",
       "21          21        0.436206\n",
       "22          22        1.864670\n",
       "23          23        0.627892\n",
       "24          24        1.342196\n",
       "25          25        0.580037\n",
       "26          26        0.422517\n",
       "27          27        0.690084\n",
       "28          28        1.085733\n",
       "29          29        4.562773\n",
       "...        ...             ...\n",
       "214170  214170        0.014722\n",
       "214171  214171        0.000000\n",
       "214172  214172        0.024767\n",
       "214173  214173        0.000000\n",
       "214174  214174        0.022054\n",
       "214175  214175        0.000000\n",
       "214176  214176        0.053593\n",
       "214177  214177        0.018077\n",
       "214178  214178        0.069392\n",
       "214179  214179        0.000000\n",
       "214180  214180        0.000000\n",
       "214181  214181        0.073648\n",
       "214182  214182        0.048884\n",
       "214183  214183        0.028534\n",
       "214184  214184        0.010463\n",
       "214185  214185        0.005024\n",
       "214186  214186        0.033654\n",
       "214187  214187        0.000000\n",
       "214188  214188        0.017341\n",
       "214189  214189        0.083648\n",
       "214190  214190        0.032685\n",
       "214191  214191        0.034964\n",
       "214192  214192        0.056704\n",
       "214193  214193        0.066949\n",
       "214194  214194        0.013876\n",
       "214195  214195        0.062951\n",
       "214196  214196        0.032276\n",
       "214197  214197        0.056092\n",
       "214198  214198        0.011112\n",
       "214199  214199        0.026709\n",
       "\n",
       "[214200 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_final = pd.DataFrame()\n",
    "predictions_final['ID'] = test['ID']\n",
    "predictions_final['item_cnt_month'] = test_pred\n",
    "predictions_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_final.to_csv('sales_output3.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
